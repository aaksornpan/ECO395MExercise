---
title: "ECO 395 Exercise1"
author: "Areeya Aksornpan, Zayd Abdalla"
date: "2/8/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown
##1) Data visualization: gas prices
```{r}
library(ggplot2)
library(tidyverse)
GasPrices = read.csv('~/Desktop/GasPrices.csv')
##A
ggplot(GasPrices, aes(x=Competitors, y=Price)) + geom_boxplot() + ggtitle("Gas Prices and Competition")
```
## This theory that gas stations charge more if they lack direct competition in sight seems plausible. The boxplot with no competition has a higher median price and its right whisker extends to higher price levels than the plot of gas stations with competition.
```{r}
##B
ggplot(GasPrices, aes(x=Income, y=Price)) + geom_point() + ggtitle("Gas Prices and Income Levels")
```
## This theory that the richer the area, the higher the gas price seems generally plausible. The scatterplot shows that as income levels increase, the prices trend to higher levels.
```{r}
##C
ggplot(GasPrices, aes(x=Brand, y=Price)) + geom_col() + ggtitle("Gas Prices and Brands")
```
## Although it is claimed that Shell charges more than other brands, this bar plot shows that the theory is only partly supported by the data. Shell's price is higher than Chevron-Texaco and Exxon Mobil, but there are other brands that sell gas in a higher price compare to Shell.
```{r}
##D
ggplot(GasPrices) + 
  geom_histogram(aes(x=Price, after_stat(density)), binwidth = 0.05) +
  facet_wrap(~Stoplight, nrow = 2) + ggtitle("Gas Prices and Stoplights")
```
##This theory that gas stations at stoplights charge more seems plausible. The bulk of gas stations near stoplights charge a price of roughly $1.9 whereas the gas stations not near stoplights charge a price of roughly $1.8.
```{r}
##E
ggplot(GasPrices, aes(x=Highway, y=Price)) + geom_boxplot() + ggtitle("Gas Prices and Highway Access")
```
## The boxplot illustrates the theory that gas stations with direct highway access charge more. The average price increases when there is direct highway access to the gas station. The minimum price increases from below $1.8 to approximately $1.85 and the maximum price increases from nearly $1.9 to close to $2.0. 
##2) Data visualization: a bike share network
```{r}
library(ggplot2)
library(tidyverse)
bikeshare = read.csv('~/Desktop/bikeshare.csv')
head(bikeshare)
##Plot A: a line graph showing average bike rentals (total) versus hour of the day (hr).
#Average bike rentals 
bikerent_total1 = bikeshare %>%
  group_by(hr) %>%
  summarize(average_bike_rental = mean(total))
#Plot the result over time in a line graph
ggplot(bikerent_total1) + 
  geom_line(aes(x=hr, y=average_bike_rental)) + scale_x_continuous(breaks = 0:24) + ggtitle("Avg Rentals and Time of Day")
```
##The x-axis is the hour which bikers rent bicycles and the y-axis is the average number of total bike rentals in that hour, including both casual and registered users. 
##The main takeaway is that bicycle renters appear to prefer renting bicycles typically around 8am and 5pm, which is before and after common working hours. There is also a slight increase from 10am to 12pm, which is when workers could have their lunch breaks. This finding may also imply the idea that people tend to leave their house around 5am and return home around 6pm. 
```{r}
##Plot B: a faceted line graph showing average bike rentals versus hour of the day, faceted according to whether it is a working day (workingday).
bikerent_total2 = bikeshare %>%
  group_by(hr, workingday) %>%
  summarize(average_bike_rental = mean(total))
head(bikerent_total2, 30)
ggplot(bikerent_total2) + 
  geom_line(aes(x=hr, y=average_bike_rental, color=workingday)) +
  facet_wrap(~workingday) + ggtitle("Avg Rentals, Time of Day, and Working Day")
```
##The x-axis is the hour which bikers rent bicycles and the y-axis is the average number of total bike rentals in that hour, including both casual and registered users.
##The left graph is the average bike rentals versus hour of weekend or holiday. Bicycle renters prefer to rent bicycles mostly around noon. It seems plausible to assume that renters started leaving the house around 6am and return home around 1pm. 
##The right graph is the average bike rentals versus hour of workingday. Bicycle renters prefer to rent bicycles mostly around 8am and 5pm, which is before and after working hours.This suggests that most renters started leaving the house around 5am and went back home around 6pm. 
```{r}
##Plot C: a faceted bar plot showing average ridership during the 8 AM hour by weather situation code (weathersit), faceted according to whether it is a working day or not. Note: remember you can focus on a specific subset of rows of a data set using filter, e.g.
bikerent_total3 = bikeshare %>%
  filter(hr==8) %>%
  group_by(weathersit, workingday) %>%
  summarise(average_bike_rental = mean(total))
head(bikerent_total3, 30)
ggplot(bikerent_total3) + 
  geom_col(aes(x=weathersit, y=average_bike_rental, color=workingday)) +
  facet_wrap(~workingday) + ggtitle("Avg Rentals at 8 A.M., Working Day, and Weather")
```
##The y-axis is average ridership at 8 A.M. and the x-axis is the weather situation, which is sorted as follows:
##1: Clear, Few clouds, Partly cloudy, Partly cloudy
##2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist
##3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds
##4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog
##The left graph is the average bike rentals versus weather situation on weekends or holidays, while the right graph is the average bike rentals versus weather situation on workdays. 
##Numbers of bike rentals on both graphs decreased as the weather situation worsened. When there is light snow, light rain with scattered clouds or thunderstorm (3), the numbers of average bike rentals lessened by half. When it is mist(2), the number of average bike rental does not decrease much compare to when it is clear or cloudy (1). Since the weather condition lessens the number of bike rentals, we could expect a fewer number of bike rentals on a snowy or rainy day. 
##3) Data visualization: flights at ABIA
```{r}
library(ggplot2)
library(tidyverse)
ABIA = read.csv('~/Desktop/ABIA.csv')
head(ABIA)
##What is the best time of year to fly to minimize delays, and does this change by destination? 
ABIA_DepDelay1 = ABIA %>%
  group_by(Month) %>%
  summarize(ABIA_total1 = mean(na.omit(DepDelay)))
Desination = c('AUS', 'DFW', 'IAH', 'PHX', 'DEN')
ABIA_DepDelay2 = ABIA %>%
  filter(Dest %in% Desination) %>%
  group_by(Month, Dest) %>%
  summarize(ABIA_total2 = mean(na.omit(DepDelay)))
head(ABIA_DepDelay1, 100)
ggplot(ABIA_DepDelay2) + 
  geom_line(aes(x=Month, y=ABIA_total2)) +
  facet_wrap(~Dest) +
  scale_x_continuous(breaks = 1:12)

ggplot(ABIA_DepDelay2) + 
  geom_line(aes(x=Month, y=ABIA_total2, color=Dest)) +
  scale_x_continuous(breaks = 1:12) + ggtitle("Annual Departure Delay in 5 U.S. Airports")
```
#All these five airports commonly have the least amount of delays in September and the most amount of delays in December, which refers that the destination does not affect the departure time and its' delay. It's possible that the weather is a major factor in delay. It could alternatively be the air traffic in December since it is the peak time of the high season.
##4) K-nearest neighbors
```{r}
library(tidyverse)
library(ggplot2)
library(rsample)
library(caret)
library(modelr)
library(parallel)
library(foreach)
sclass = read.csv('~/Desktop/sclass.csv')
##350
model350 = sclass %>%
  filter(trim %in% '350')
#1.Split the data into a training and a testing set.

sclass350_split =  initial_split(model350, prop=0.9)
sclass350_train = training(sclass350_split)
sclass350_test  = testing(sclass350_split)
#2.Run K-nearest-neighbors, for many different values of K, starting at K=2 and going as high as you need to. For each value of K, fit the model to the training set and make predictions on your test set.
K_folds = 5
model350 = model350 %>%
  mutate(fold_id = rep(1:K_folds, length=nrow(model350)) %>% sample)
head(model350)
#3.Calculate the out-of-sample root mean-squared error (RMSE) for each value of K.
rmse_cv = foreach(fold = 1:K_folds, .combine='c') %do% {
  knn100 = knnreg(price ~ mileage,
                  data=filter(model350, fold_id != fold), k=100)
  modelr::rmse(knn100, data=filter(model350, fold_id == fold))
}
k_grid = c(2, 3, 4, 6, 8, 10, 15, 20, 25, 30, 35, 40, 45,
           50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100)
model350_folds = crossv_kfold(model350, k=K_folds)
cv_grid = foreach(k = k_grid, .combine='rbind') %dopar% {
  models = map(model350_folds$train, ~ knnreg(price ~ mileage, k=k, data = ., use.all=FALSE))
  errs = map2_dbl(models, model350_folds$test, modelr::rmse)
  c(k=k, err = mean(errs), std_err = sd(errs)/sqrt(K_folds))
} %>% as.data.frame
head(cv_grid)
#RMSE versus K plot
ggplot(cv_grid) + 
  geom_line(aes(x=k, y=err)) + 
  geom_errorbar(aes(x=k, ymin = err-std_err, ymax = err+std_err)) +
  scale_x_log10() + ggtitle("RMSE vs K")
#For the optimal value of K (k=10), plot of the fitted model i.e. price prediction vs. mileage
knn10 = knnreg(price ~ mileage, data=sclass350_train, k=10)
sclass350_test = sclass350_test %>%
  mutate(price_pred = predict(knn10, sclass350_test))
p_test = ggplot(data = sclass350_test) + 
  geom_point(mapping = aes(x = mileage, y = price), alpha=0.2) + ggtitle("Price and Mileage")
p_test
p_test + geom_line(aes(x = mileage, y = price_pred), color='red', size=0.5) + ggtitle("Predicted Price vs Actual Price and Mileage")
##65 AMG
model65AMG = sclass %>%
  filter(trim %in% '65 AMG')
#1.Split the data into a training and a testing set.
sclass65AMG_split =  initial_split(model65AMG, prop=0.9)
sclass65AMG_train = training(sclass65AMG_split)
sclass65AMG_test  = testing(sclass65AMG_split)
#2.Run K-nearest-neighbors, for many different values of K, starting at K=2 and going as high as you need to. For each value of K, fit the model to the training set and make predictions on your test set.
K_folds = 5
model65AMG = model65AMG %>%
  mutate(fold_id = rep(1:K_folds, length=nrow(model65AMG)) %>% sample)
#3.Calculate the out-of-sample root mean-squared error (RMSE) for each value of K.
rmse_cv = foreach(fold = 1:K_folds, .combine='c') %do% {
  knn100 = knnreg(price ~ mileage,
                  data=filter(model65AMG, fold_id != fold), k=100)
  modelr::rmse(knn100, data=filter(model350, fold_id == fold))
}
k_grid = c(2, 3, 4, 6, 8, 10, 15, 20, 25, 30, 35, 40, 45,
           50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100)
model65AMG_folds = crossv_kfold(model65AMG, k=K_folds)
cv_grid = foreach(k = k_grid, .combine='rbind') %dopar% {
  models = map(model65AMG_folds$train, ~ knnreg(price ~ mileage, k=k, data = ., use.all=FALSE))
  errs = map2_dbl(models, model65AMG_folds$test, modelr::rmse)
  c(k=k, err = mean(errs), std_err = sd(errs)/sqrt(K_folds))
} %>% as.data.frame
head(cv_grid)
#RMSE versus K plot
ggplot(cv_grid) + 
  geom_line(aes(x=k, y=err)) + 
  geom_errorbar(aes(x=k, ymin = err-std_err, ymax = err+std_err)) +
  scale_x_log10() + ggtitle("RMSE vs K")
#For the optimal value of K (k=15), plot of the fitted model i.e. price prediction vs. mileage
knn15 = knnreg(price ~ mileage, data=sclass65AMG_train, k=15)
sclass65AMG_test = sclass65AMG_test %>%
  mutate(price_pred = predict(knn10, sclass65AMG_test))
p_test = ggplot(data = sclass65AMG_test) + 
  geom_point(mapping = aes(x = mileage, y = price), alpha=0.2) + ggtitle("Price and Mileage")
p_test
p_test + geom_line(aes(x = mileage, y = price_pred), color='red', size=0.5) + ggtitle("Predicted Price vs Actual Price and Mileage")
```
##The 65 AMG yields a larger optimal value of K. The lowest out-of-sample root mean-squared error of the 65 AMG is lower than the 350. I think this occurs due to the difference in sample sizes since the 65 AMG S-Class has 292 observations whereas the 350 S-class has 416 observations. 